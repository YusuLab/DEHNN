{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cf15dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from pyg_dataset import pyg_dataset as pyg\n",
    "from pyg_dataset_net import pyg_dataset as pyg_net\n",
    "from pyg_dataset_sparse import pyg_dataset as pyg_sparse\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3b7aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a8cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd5f0fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning target: hpwl\n",
      "Data(x=[821523, 41], num_instances=797938, y=[821523, 1], edge_index_node_net=[2, 2950019], edge_index_net_node=[2, 2950019], edge_index_node_node=[2, 5998176], edge_attr=[2, 1], evects=[821523, 10], evals=[0], cell_degrees=[797938], net_degrees=[821523]) 0\n",
      "Learning target: hpwl\n",
      "Data(x=[797938, 34], x_net=[821523, 7], y=[821523, 1], net_inst_adj=[821523, 797938], inst_net_adj_v_drive=[797938, 821523], inst_net_adj_v_sink=[797938, 821523], num_instances=797938, evects=[1619461, 10], evals=[10], num_edges=2950019, cell_degrees=[797938], net_degrees=[821523]) 0\n"
     ]
    }
   ],
   "source": [
    "graph_index = 0\n",
    "dataset1 = pyg_net('../../data/2023-03-06_data/', graph_index = graph_index, target = 'hpwl', load_pe = True, num_eigen = 10, load_global_info = False, load_pd = True, vn=False, net=True, concat=True)\n",
    "data1 = dataset1[0]\n",
    "\n",
    "dataset2 = pyg_sparse('../../data/2023-03-06_data/', graph_index = graph_index, target = 'hpwl', load_pe = True, num_eigen = 10, load_global_info = False, load_pd = True, vn=False, net=True)\n",
    "data2 = dataset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc1c770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperedge_index = data2.net_inst_adj.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d104811a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      0,      0,  ..., 797937, 797937, 797937])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperedge_index.coalesce().indices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c666d9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821523"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperedge_index.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "681188b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[612254, 612365, 612476, 612587]]),\n",
       "       values=tensor([1., 1., 1., 1.]),\n",
       "       size=(821523,), nnz=4, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperedge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d3fb183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[612698, 612809, 612920, 613031, 613142]]),\n",
       "       values=tensor([1., 1., 1., 1., 1.]),\n",
       "       size=(821523,), nnz=5, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperedge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad905721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning target: demand\n",
      "Data(x=[459495, 34], y=[468888, 1], net_inst_adj=[468888, 459495], inst_net_adj_v_drive=[459495, 468888], inst_net_adj_v_sink=[459495, 468888], x_net=[468888, 7]) 40\n",
      "Learning target: demand\n",
      "Data(x=[459495, 34], y=[468888, 1], net_inst_adj=[468888, 459495], inst_net_adj_v_drive=[459495, 468888], inst_net_adj_v_sink=[459495, 468888], x_net=[468888, 7]) 41\n",
      "Learning target: demand\n",
      "Data(x=[459495, 34], y=[468888, 1], net_inst_adj=[468888, 459495], inst_net_adj_v_drive=[459495, 468888], inst_net_adj_v_sink=[459495, 468888], x_net=[468888, 7]) 42\n",
      "Learning target: demand\n",
      "Data(x=[459495, 34], y=[468888, 1], net_inst_adj=[468888, 459495], inst_net_adj_v_drive=[459495, 468888], inst_net_adj_v_sink=[459495, 468888], x_net=[468888, 7]) 43\n",
      "Learning target: demand\n",
      "Data(x=[495234, 34], y=[510258, 1], net_inst_adj=[510258, 495234], inst_net_adj_v_drive=[495234, 510258], inst_net_adj_v_sink=[495234, 510258], x_net=[510258, 7]) 44\n",
      "Learning target: demand\n",
      "Data(x=[495234, 34], y=[510258, 1], net_inst_adj=[510258, 495234], inst_net_adj_v_drive=[495234, 510258], inst_net_adj_v_sink=[495234, 510258], x_net=[510258, 7]) 45\n",
      "Learning target: demand\n",
      "Data(x=[495234, 34], y=[510258, 1], net_inst_adj=[510258, 495234], inst_net_adj_v_drive=[495234, 510258], inst_net_adj_v_sink=[495234, 510258], x_net=[510258, 7]) 46\n",
      "Learning target: demand\n",
      "Data(x=[495234, 34], y=[510258, 1], net_inst_adj=[510258, 495234], inst_net_adj_v_drive=[495234, 510258], inst_net_adj_v_sink=[495234, 510258], x_net=[510258, 7]) 47\n",
      "Learning target: demand\n",
      "Data(x=[495234, 34], y=[510258, 1], net_inst_adj=[510258, 495234], inst_net_adj_v_drive=[495234, 510258], inst_net_adj_v_sink=[495234, 510258], x_net=[510258, 7]) 48\n",
      "Learning target: demand\n",
      "Data(x=[495234, 34], y=[510258, 1], net_inst_adj=[510258, 495234], inst_net_adj_v_drive=[495234, 510258], inst_net_adj_v_sink=[495234, 510258], x_net=[510258, 7]) 49\n"
     ]
    }
   ],
   "source": [
    "for graph_index in range(0, 50):\n",
    "\n",
    "    dataset = pyg_dataset('../../data/2023-03-06_data/', graph_index = graph_index, target = 'demand', load_pe = False, num_eigen = 0, load_global_info = False, load_pd = True, vn=False, net=True)\n",
    "    data = dataset[0]\n",
    "\n",
    "    x = data.x.to(device)\n",
    "    net_inst_adj = data.net_inst_adj.to(device)\n",
    "    x_net = data.x_net.to(device)\n",
    "    y = data.y.to(device).flatten()\n",
    "\n",
    "    net_agg = torch.mm(net_inst_adj, x)\n",
    "\n",
    "    net_all = torch.cat([net_agg, x_net], dim=1)\n",
    "\n",
    "    dictionary = {'instance_features': net_all.numpy()}\n",
    "\n",
    "    f = open('../../data/2023-03-06_data/' + str(graph_index) + '.net_features.pkl', 'wb')\n",
    "    pickle.dump(dictionary, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99ad03d7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df255310435d4087833d9feac9faa845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-90e90e99df6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mhpwl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.node_features.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0md_node_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "for graph_index in tqdm(range(0, 50)):\n",
    "    \n",
    "    data_dir = \"../../data/2023-03-06_data/\"\n",
    "    target = 'hpwl'\n",
    "\n",
    "    file_name = data_dir + '/' + str(graph_index) + '.net_demand_capacity.pkl'\n",
    "    f = open(file_name, 'rb')\n",
    "    dictionary = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    if target == 'hpwl':\n",
    "        fn = data_dir + '/' + str(graph_index) + '.net_hpwl.pkl'\n",
    "        f = open(fn, \"rb\")\n",
    "        d_hpwl = pickle.load(f)\n",
    "        f.close()\n",
    "        hpwl_net = d_hpwl['hpwl_net']\n",
    "        nets = d_hpwl['nets']\n",
    "\n",
    "    demand = dictionary['demand']\n",
    "    capacity = dictionary['capacity']\n",
    "    \n",
    "    all_nets = np.unique(nets)\n",
    "    hpwl = [0.0 for idx in range(len(demand))]\n",
    "    \n",
    "    for idx in range(len(hpwl_net)):\n",
    "        net = nets[idx]\n",
    "        wl = hpwl_net[idx]\n",
    "        hpwl[net] = wl\n",
    "    \n",
    "    d_hpwl['hpwl'] = hpwl\n",
    "    \n",
    "    fn = data_dir + '/' + str(graph_index) + '.net_hpwl.pkl'\n",
    "    f = open(fn, \"wb\")\n",
    "    pickle.dump(d_hpwl, f)\n",
    "    f.close()\n",
    "    \n",
    "    print(graph_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f1a8dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000],\n",
       "        [0.1667],\n",
       "        [0.1667],\n",
       "        [0.1667],\n",
       "        [0.1667],\n",
       "        [0.2000],\n",
       "        [0.1250],\n",
       "        [0.2000],\n",
       "        [0.1667],\n",
       "        [0.1667]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./deg.view(-1,1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a359995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_index = 8\n",
    "\n",
    "data_dir = \"../../data/2023-03-06_data/\"\n",
    "fn = data_dir + '/' + str(graph_index) + '.net_hpwl.pkl'\n",
    "f = open(fn, \"rb\")\n",
    "dictionary = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb3a63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpwl = dictionary['orig_hpwl']\n",
    "#dictionary['orig_hpwl'] = hpwl\n",
    "where_lst = [num > 0.1 for num in hpwl]\n",
    "new_hpwl = np.log10(hpwl, where=where_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4debb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log10_except_0(a):\n",
    "    output = []\n",
    "    for num in a:\n",
    "        if num == 0:\n",
    "            output.append(0)\n",
    "        else:\n",
    "            output.append(np.log10(num))\n",
    "    output = np.array(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bddca6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for graph_index in range(50):\n",
    "    data_dir = \"../../data/2023-03-06_data/\"\n",
    "    fn = data_dir + '/' + str(graph_index) + '.net_hpwl.pkl'\n",
    "    f = open(fn, \"rb\")\n",
    "    dictionary = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    hpwl = dictionary['orig_hpwl']\n",
    "    #dictionary['orig_hpwl'] = hpwl\n",
    "    new_hpwl = log10_except_0(hpwl)\n",
    "    dictionary['hpwl'] = new_hpwl\n",
    "    \n",
    "    fn = data_dir + '/' + str(graph_index) + '.net_hpwl.pkl'\n",
    "    f = open(fn, \"wb\")\n",
    "    pickle.dump(dictionary, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9514ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 7.2791968122439155\n",
      "0.0 7.1625763539372755\n",
      "0.0 7.172923280330212\n",
      "0.0 7.1999508946740605\n",
      "0.0 7.221924136595014\n",
      "0.0 7.465454533868038\n",
      "0.0 7.374716459928258\n",
      "0.0 7.314337416296302\n",
      "0.0 7.409554429230712\n",
      "0.0 7.449539797761351\n",
      "0.0 7.303698770111628\n",
      "0.0 7.203029621630391\n",
      "0.0 7.097317710960456\n",
      "0.0 7.173853083227975\n",
      "0.0 7.184444408814976\n",
      "0.0 7.19587696892035\n",
      "0.0 7.157342512804119\n",
      "0.0 7.069269132238363\n",
      "0.0 7.093205885264876\n",
      "0.0 7.0921660214797395\n",
      "0.0 7.1189244317759135\n",
      "0.0 7.289329814574371\n",
      "0.0 7.072434461125585\n",
      "0.0 7.2566354963773\n",
      "0.0 7.244428540682831\n",
      "0.0 7.226820475937463\n",
      "0.0 7.072434461125585\n",
      "0.0 7.253102860402543\n",
      "0.0 7.197355002227491\n",
      "0.0 7.215284803750691\n",
      "0.0 7.174209297977475\n",
      "0.0 7.20949249498565\n",
      "0.0 7.1839823561817955\n",
      "0.0 7.288942826956648\n",
      "0.0 7.211559421595917\n",
      "0.0 7.242484280527803\n",
      "0.0 7.203776754422211\n",
      "0.0 7.246123211825972\n",
      "0.0 7.205278545073779\n",
      "0.0 7.081077500490495\n",
      "0.0 7.003220052525283\n",
      "0.0 6.937449181797029\n",
      "0.0 7.000542529092294\n",
      "0.0 6.99161322285475\n",
      "0.0 7.143989150599658\n",
      "0.0 7.05478076554166\n",
      "0.0 6.975247021708728\n",
      "0.0 7.0819626623316445\n",
      "0.0 7.067280695734973\n",
      "0.0 7.0526231565422375\n"
     ]
    }
   ],
   "source": [
    "for graph_index in range(50):\n",
    "    data_dir = \"../../data/2023-03-06_data/\"\n",
    "    fn = data_dir + '/' + str(graph_index) + '.net_hpwl.pkl'\n",
    "    f = open(fn, \"rb\")\n",
    "    dictionary = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    print(min(dictionary['hpwl']), max(dictionary['hpwl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5bab5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_index in range(1, 50):\n",
    "    file_name = data_dir + '/' + str(graph_index) + '.targets.pkl'\n",
    "    f = open(file_name, 'rb')\n",
    "    dictionary = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    dictionary['demand'] = dictionary['demand'] * 5\n",
    "    dictionary['capacity'] = dictionary['capacity'] * 5\n",
    "    \n",
    "    fn = data_dir + '/' + str(graph_index) + '.targets.pkl'\n",
    "    f = open(fn, \"wb\")\n",
    "    pickle.dump(dictionary, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5754249",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = data_dir + '/' + str(graph_index) + '.net_demand_capacity.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18c5f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_index = 22\n",
    "\n",
    "file_name = data_dir + '/' + str(graph_index) + '.targets.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c261d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demand': array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 'capacity': array([20., 20., 20., ..., 20., 20., 20.]),\n",
       " 'classify': tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08fbf8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning target: demand\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[495234, 46], num_instances=495234, y=[495234, 1], edge_index_node_net=[2, 1775530], edge_index_net_node=[2, 1775530], edge_index_node_node=[2, 3257420], edge_attr=[2, 1], x_net=[510258, 4])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_index = 44\n",
    "dataset = pyg_dataset('../../data/2023-03-06_data/', graph_index = graph_index, target = 'demand', load_pe = False, num_eigen = 0, load_global_info = True, load_pd = True, vn=False, concat=False)\n",
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f824a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[797938, 46], num_instances=797938, y=[797938, 1], edge_index_node_net=[2, 2950019], edge_index_net_node=[2, 2950019], edge_index_node_node=[2, 5998176], edge_attr=[2, 1], x_net=[821523, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f20784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demand': array([ 0.        ,  0.        ,  0.        , ...,  2.5       ,\n",
       "        10.83333333,  5.        ]),\n",
       " 'capacity': array([21.66666667, 23.33333333, 23.33333333, ...,  3.33333333,\n",
       "        25.        ,  3.33333333]),\n",
       " 'classify': tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [1]])}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = data_dir + '/' + str(graph_index) + '.targets.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4609acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demand': array([ 5.        , 40.        ,  7.5       , ...,  5.        ,\n",
       "        15.        ,  0.83333333]),\n",
       " 'capacity': array([ 3.33333333, 18.33333333,  3.33333333, ...,  3.33333333,\n",
       "        23.33333333,  1.66666667]),\n",
       " 'classify': tensor([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [0],\n",
       "         [0]])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = data_dir + '/' + str(graph_index) + '.targets.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "138e69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "file_name = data_dir + '/' + str(sample) + '.node_features.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "num_instances = dictionary['num_instances']\n",
    "num_nets = dictionary['num_nets']\n",
    "instance_features = torch.Tensor(dictionary['instance_features'])\n",
    "instance_features = instance_features[:, 2:]\n",
    "net_features = torch.zeros(num_nets, instance_features.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "183ff368",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "file_name = data_dir + '/' + str(sample) + '.node_features.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "num_instances = dictionary['num_instances']\n",
    "num_nets = dictionary['num_nets']\n",
    "instance_features = torch.Tensor(dictionary['instance_features'])\n",
    "instance_features = instance_features[:, 2:]\n",
    "net_features = torch.zeros(num_nets, instance_features.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dad4734e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3200e+02, 3.9980e-04, 0.0000e+00,  ..., 1.0000e+00, 3.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [3.5900e+02, 7.9960e-04, 0.0000e+00,  ..., 1.0000e+00, 4.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [1.7600e+02, 4.9975e-04, 0.0000e+00,  ..., 1.0000e+00, 4.0000e+00,\n",
       "         1.0000e+00],\n",
       "        ...,\n",
       "        [6.0000e+00, 1.5992e-03, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [6.0000e+00, 1.5992e-03, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [6.0000e+00, 1.5992e-03, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7aab0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 1\n",
    "file_name = data_dir + '/' + str(sample) + '.node_features.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "num_instances = dictionary['num_instances']\n",
    "num_nets = dictionary['num_nets']\n",
    "instance_features = torch.Tensor(dictionary['instance_features'])\n",
    "instance_features = instance_features[:, 2:]\n",
    "net_features = torch.zeros(num_nets, instance_features.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc5b7cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3200e+02, 3.9980e-04, 0.0000e+00, 6.0000e+00],\n",
       "        [3.5900e+02, 7.9960e-04, 0.0000e+00, 6.0000e+00],\n",
       "        [1.7600e+02, 4.9975e-04, 0.0000e+00, 0.0000e+00],\n",
       "        ...,\n",
       "        [6.0000e+00, 1.5992e-03, 0.0000e+00, 6.0000e+00],\n",
       "        [6.0000e+00, 1.5992e-03, 0.0000e+00, 0.0000e+00],\n",
       "        [6.0000e+00, 1.5992e-03, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3cde5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "file_name = data_dir + '/' + str(sample) + '.node_neighbor_features.pkl'\n",
    "f = open(file_name, 'rb')\n",
    "dictionary = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acb58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
